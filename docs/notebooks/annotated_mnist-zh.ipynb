{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9q9JZjt16AMf"
   },
   "source": [
    "[![Open in Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/google/flax/blob/main/docs/notebooks/annotated_mnist.ipynb)\n",
    "[![Open On GitHub](https://img.shields.io/badge/Open-on%20GitHub-blue?logo=GitHub)](https://github.com/google/flax/blob/main/docs/notebooks/annotated_mnist.ipynb)\n",
    "\n",
    "# MNIST ğŸŒ°\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VSaA8Mif6srP"
   },
   "source": [
    "## 1. Imports\n",
    "\n",
    "Import JAX, [JAX NumPy](https://jax.readthedocs.io/en/latest/jax.numpy.html),\n",
    "Flax, ordinary NumPy, and TensorFlow Datasets (TFDS). \n",
    "\n",
    "Flaxæ”¯æŒä»»æ„çš„æ•°æ®è¯»å–æ¨¡å—ï¼Œä¸é™äºTensorFlowã€PyTorchç­‰ç­‰ã€‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "inJ9bV636dRx",
    "tags": [
     "skip-execution"
    ]
   },
   "outputs": [],
   "source": [
    "!pip3 install -q flax tensorflow_datasets tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "Z7MuGFB16E8m"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-07-12 09:35:16.552063: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: :/usr/local/lib\n"
     ]
    }
   ],
   "source": [
    "import jax\n",
    "import jax.numpy as jnp                # JAX NumPy\n",
    "\n",
    "from flax import linen as nn           # The Linen API\n",
    "from flax.training import train_state  # Useful dataclass to keep train state\n",
    "\n",
    "import numpy as np                     # Ordinary NumPy\n",
    "import optax                           # Optimizers\n",
    "import tensorflow_datasets as tfds     # TFDS for MNIST"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "d0FW1DHa6cfH"
   },
   "source": [
    "## 2. å®šä¹‰ç½‘ç»œ\n",
    "\n",
    "åŒPyTorchï¼Œéœ€è¦ç»§æ‰¿\n",
    "[Module](https://flax.readthedocs.io/en/latest/flax.linen.html#core-module-abstraction)ï¼Œç„¶åå®šä¹‰ç½‘ç»œå³å¯ã€‚\n",
    "\n",
    "æœ¬ç¤ºä¾‹ç”¨çš„ç½‘ç»œéå¸¸ç®€å•ï¼Œæ‰€ä»¥å¯ä»¥ç›´æ¥åœ¨`__call__` ä¸­å®šä¹‰å­modulesï¼Œå†ä½¿ç”¨\n",
    "[@compact](https://flax.readthedocs.io/en/latest/flax.linen.html#compact-methods)ã€‚æ³¨æ„ï¼šModuleç±»ä¸­æœ€å¤šæœ‰ä¸€ä¸ªæ–¹æ³•å¯ä»¥è¢«`@compact`ä¿®é¥°ã€‚\n",
    "\n",
    "\n",
    "å¦‚æœç½‘ç»œå¾ˆå¤æ‚ï¼Œéœ€è¦å€ŸåŠ©`setup()`å’Œä¸€äº›data fields."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "_s1lXBBO66dc"
   },
   "outputs": [],
   "source": [
    "class CNN(nn.Module):\n",
    "  \"\"\"A simple CNN model.\"\"\"\n",
    "\n",
    "  @nn.compact\n",
    "  def __call__(self, x):\n",
    "    x = nn.Conv(features=32, kernel_size=(3, 3))(x)\n",
    "    x = nn.relu(x)\n",
    "    x = nn.avg_pool(x, window_shape=(2, 2), strides=(2, 2))\n",
    "    x = nn.Conv(features=64, kernel_size=(3, 3))(x)\n",
    "    x = nn.relu(x)\n",
    "    x = nn.avg_pool(x, window_shape=(2, 2), strides=(2, 2))\n",
    "    x = x.reshape((x.shape[0], -1))  # flatten\n",
    "    x = nn.Dense(features=256)(x)\n",
    "    x = nn.relu(x)\n",
    "    x = nn.Dense(features=10)(x)\n",
    "    return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xDEoAprU6_JZ"
   },
   "source": [
    "## 3. å®šä¹‰ loss\n",
    "\n",
    "ä½¿ç”¨äº¤å‰ç†µæŸå¤±å‡½æ•° `optax.softmax_cross_entropy()`ï¼Œ è¿™ä¸ªå‡½æ•°è¦æ±‚ `logits` å’Œ `labels` çš„shapeæ˜¯ `[batch, num_classes]`ï¼Œæˆ‘ä»¬éœ€è¦å°†æ•´æ•°labelè½¬æ¢ä¸ºone-hotã€‚\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "Zcb_ebU87G7s"
   },
   "outputs": [],
   "source": [
    "# def cross_entropy_loss(*, logits, labels):\n",
    "def cross_entropy_loss(logits, labels):\n",
    "  labels_onehot = jax.nn.one_hot(labels, num_classes=10)\n",
    "  return optax.softmax_cross_entropy(logits=logits, labels=labels_onehot).mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "INZE3eM67JUr"
   },
   "source": [
    "## 4. Metric computation\n",
    "\n",
    "For loss and accuracy metrics, create a separate function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "KvuEA8Tw-MYa"
   },
   "outputs": [],
   "source": [
    "# def compute_metrics(*, logits, labels):\n",
    "def compute_metrics(logits, labels):\n",
    "  loss = cross_entropy_loss(logits=logits, labels=labels)\n",
    "  accuracy = jnp.mean(jnp.argmax(logits, -1) == labels)\n",
    "  metrics = {\n",
    "      'loss': loss,\n",
    "      'accuracy': accuracy,\n",
    "  }\n",
    "  return metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lYz0Emry-ele"
   },
   "source": [
    "## 5. Loading data\n",
    "\n",
    "Define a function that loads and prepares the MNIST dataset and converts the\n",
    "samples to floating-point numbers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "IOeWiS_b-p8O"
   },
   "outputs": [],
   "source": [
    "def get_datasets():\n",
    "  \"\"\"Load MNIST train and test datasets into memory.\"\"\"\n",
    "  ds_builder = tfds.builder('mnist')\n",
    "  ds_builder.download_and_prepare()\n",
    "  train_ds = tfds.as_numpy(ds_builder.as_dataset(split='train', batch_size=-1))\n",
    "  test_ds = tfds.as_numpy(ds_builder.as_dataset(split='test', batch_size=-1))\n",
    "  train_ds['image'] = jnp.float32(train_ds['image']) / 255.\n",
    "  test_ds['image'] = jnp.float32(test_ds['image']) / 255.\n",
    "  return train_ds, test_ds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UMFK51rsAUX4"
   },
   "source": [
    "## 6. Create train state\n",
    "\n",
    "* å¾ˆå…³é”®\n",
    "\n",
    "\n",
    "ç”±äºJAXå±äºå‡½æ•°å¼ç¼–ç¨‹ï¼Œå»ºè®®åˆ›å»ºä¸€ä¸ªå•ç‹¬çš„dataclassæ¥åŒ…å«æ‰€æœ‰çš„è®­ç»ƒçŠ¶æ€ï¼Œæ¯”å¦‚ step number, parameters, and optimizer stateã€‚Flaxä¸­æä¾›äº†ä¸€ä¸ªç±»[flax.training.train_state.TrainState](https://flax.readthedocs.io/en/latest/flax.training.html#train-state)\n",
    "ï¼Œæˆ‘ä»¬å¯ä»¥ç»§æ‰¿å®ƒç„¶ååˆ›å»ºè‡ªå·±çš„TrainStateï¼Œæ·»åŠ æ›´å¤šéœ€è¦è¢«trackçš„æ•°æ®å³å¯ï¼Œä½†æ˜¯æœ¬æ–‡çš„ä¾‹å­å¾ˆç®€å•ï¼Œæˆ‘ä»¬ä¸éœ€è¦ä¿®æ”¹TrainStateã€‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "QadyBPbWBEAT"
   },
   "outputs": [],
   "source": [
    "def create_train_state(rng, learning_rate, momentum):\n",
    "  \"\"\"Creates initial `TrainState`.\"\"\"\n",
    "  cnn = CNN()\n",
    "  params = cnn.init(rng, jnp.ones([1, 28, 28, 1]))['params']  # ['params']\n",
    "  tx = optax.sgd(learning_rate, momentum)\n",
    "  return train_state.TrainState.create(\n",
    "      apply_fn=cnn.apply,\n",
    "      params=params, \n",
    "      tx=tx)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "W7l-75YE-sr-"
   },
   "source": [
    "## 7. Training step\n",
    "\n",
    "å¾ˆé‡è¦çš„ä¸€ä¸ªå‡½æ•°ï¼Œå°±æ˜¯ä¸€ä¸ªstepçš„å®Œæ•´çš„è®­ç»ƒæµç¨‹:\n",
    "\n",
    "- Evaluates the neural network given the parameters and a batch of input images\n",
    "  with the\n",
    "  [Module.apply](https://flax.readthedocs.io/en/latest/flax.linen.html#flax.linen.Module.apply)\n",
    "  method.\n",
    "- Computes the `cross_entropy_loss` loss function.\n",
    "- Evaluates the loss function and its gradient using\n",
    "  [jax.value_and_grad](https://jax.readthedocs.io/en/latest/jax.html#jax.value_and_grad).\n",
    "- Applies a\n",
    "  [pytree](https://jax.readthedocs.io/en/latest/pytrees.html#pytrees-and-jax-functions)\n",
    "  of gradients to the optimizer to update the model's parameters.\n",
    "- Computes the metrics using `compute_metrics` (defined earlier).\n",
    "\n",
    "ä½¿ç”¨JAXçš„[@jit](https://jax.readthedocs.io/en/latest/jax.html#jax.jit)æ¥è¿›è¡ŒJITç¼–è¯‘ï¼Œè®©XLAè¿›è¡Œä¼˜åŒ–ï¼Œæä¾›æ‰§è¡Œæ•ˆç‡ã€‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "Ng11cdMf-z0x"
   },
   "outputs": [],
   "source": [
    "@jax.jit\n",
    "def train_step(state, batch):\n",
    "  \"\"\"Train for a single step.\"\"\"\n",
    "  def loss_fn(params):\n",
    "    logits = CNN().apply({'params': params}, batch['image'])  # CNN().applyï¼Œéƒ½ä¸éœ€è¦åˆ›å»ºCNNçš„ç¤ºä¾‹ï¼Œçº¯å‡½æ•°å¼\n",
    "    loss = cross_entropy_loss(logits=logits, labels=batch['label'])\n",
    "    return loss, logits\n",
    "  grad_fn = jax.value_and_grad(loss_fn, has_aux=True)  # has_aux\n",
    "  (_, logits), grads = grad_fn(state.params)\n",
    "  state = state.apply_gradients(grads=grads)\n",
    "  metrics = compute_metrics(logits=logits, labels=batch['label'])\n",
    "  return state, metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "t-4qDNUgBryr"
   },
   "source": [
    "## 8. Evaluation step\n",
    "\n",
    "Create a function that evaluates your model on the test set with\n",
    "[Module.apply](https://flax.readthedocs.io/en/latest/flax.linen.html#flax.linen.Module.apply)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "w1J9i6alBv_u"
   },
   "outputs": [],
   "source": [
    "@jax.jit\n",
    "def eval_step(params, batch):\n",
    "  logits = CNN().apply({'params': params}, batch['image'])\n",
    "  return compute_metrics(logits=logits, labels=batch['label'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MBTLQPC4BxgH"
   },
   "source": [
    "## 9. Train function\n",
    "\n",
    "æ¯ä¸ªepochçš„è®­ç»ƒå‡½æ•°:\n",
    "\n",
    "- æ¯ä¸ªepochå‰å¯¹è®­ç»ƒé›†shuffle\n",
    "  [jax.random.permutation](https://jax.readthedocs.io/en/latest/_autosummary/jax.random.permutation.html)\n",
    "- Runs an optimization step for each batch.\n",
    "- ä½¿ç”¨`jax.device_get`ä»deviceä¸­å–å›æ¯ä¸ªminibatchçš„metricï¼Œè®¡ç®—æ•´ä¸ªepochçš„metric\n",
    "- Returns the optimizer with updated parameters and the training loss and\n",
    "  accuracy metrics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = jnp.array([[1,2,3], [4,5,6]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rng = jax.random.PRNGKey(0)\n",
    "y = jax.random.permutation(rng, 6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(y), type(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "7ipyJ-JGCNqP"
   },
   "outputs": [],
   "source": [
    "def train_epoch(state, train_ds, batch_size, epoch, rng):\n",
    "  \"\"\"Train for a single epoch.\"\"\"\n",
    "  train_ds_size = len(train_ds['image'])\n",
    "  steps_per_epoch = train_ds_size // batch_size\n",
    "\n",
    "  perms = jax.random.permutation(rng, train_ds_size)  # permså°±æ˜¯shuffleåçš„range(n)\n",
    "  perms = perms[:steps_per_epoch * batch_size]  # skip incomplete batchï¼Œè¿™é‡Œä¿è¯æ¯ä¸ªbatchæ•°æ®é‡ç›¸åŒï¼Œå¦åˆ™æ¶‰åŠåˆ°å‡½æ•°é‡ç¼–è¯‘\n",
    "  perms = perms.reshape((steps_per_epoch, batch_size))\n",
    "  batch_metrics = []\n",
    "  for perm in perms:\n",
    "    batch = {k: v[perm, ...] for k, v in train_ds.items()}  # v[perm, ...] æ˜¯???\n",
    "#     print(batch)  # {'image': }\n",
    "    break\n",
    "    state, metrics = train_step(state, batch)\n",
    "    batch_metrics.append(metrics)\n",
    "\n",
    "  # compute mean of metrics across each batch in epoch.\n",
    "  batch_metrics_np = jax.device_get(batch_metrics)\n",
    "  epoch_metrics_np = {\n",
    "      k: np.mean([metrics[k] for metrics in batch_metrics_np])\n",
    "      for k in batch_metrics_np[0]}\n",
    "\n",
    "  print('train epoch: %d, loss: %.4f, accuracy: %.2f' % (\n",
    "      epoch, epoch_metrics_np['loss'], epoch_metrics_np['accuracy'] * 100))\n",
    "\n",
    "  return state"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "E2cHbVUfCRMv"
   },
   "source": [
    "## 10. Eval function\n",
    "\n",
    "Create a model evaluation function that:\n",
    "\n",
    "- Retrieves the evaluation metrics from the device with `jax.device_get`.\n",
    "- Copies the metrics\n",
    "  [data stored](https://flax.readthedocs.io/en/latest/design_notes/linen_design_principles.html#how-are-parameters-represented-and-how-do-we-handle-general-differentiable-algorithms-that-update-stateful-variables)\n",
    "  in a JAX\n",
    "  [pytree](https://jax.readthedocs.io/en/latest/pytrees.html#pytrees-and-jax-functions)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "_dKahNmMCr5q"
   },
   "outputs": [],
   "source": [
    "def eval_model(params, test_ds):\n",
    "  metrics = eval_step(params, test_ds)  # ä¸€ä¸ªbatch...\n",
    "  metrics = jax.device_get(metrics)\n",
    "  summary = jax.tree_map(lambda x: x.item(), metrics)\n",
    "  return summary['loss'], summary['accuracy']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mHQi20yVCsSf"
   },
   "source": [
    "## 11. Download data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "6CLXnP3KHptR",
    "outputId": "4f019877-e87d-4862-af7b-c82334e4f12c"
   },
   "outputs": [],
   "source": [
    "train_ds, test_ds = get_datasets()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "56rKPl6OHqu8"
   },
   "source": [
    "## 12. Seed randomness\n",
    "\n",
    "- Get one\n",
    "  [PRNGKey](https://jax.readthedocs.io/en/latest/_autosummary/jax.random.PRNGKey.html#jax.random.PRNGKey)\n",
    "  and\n",
    "  [split](https://jax.readthedocs.io/en/latest/_autosummary/jax.random.split.html#jax.random.split)\n",
    "  it to get a second key that you'll use for parameter initialization. (Learn\n",
    "  more about\n",
    "  [PRNG chains](https://flax.readthedocs.io/en/latest/design_notes/linen_design_principles.html#how-are-parameters-represented-and-how-do-we-handle-general-differentiable-algorithms-that-update-stateful-variables)\n",
    "  and\n",
    "  [JAX PRNG design](https://github.com/google/jax/blob/main/design_notes/prng.md).)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "n53xh_B8Ht_W"
   },
   "outputs": [],
   "source": [
    "rng = jax.random.PRNGKey(0)\n",
    "rng, init_rng = jax.random.split(rng)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Y3iHFiAuH41s"
   },
   "source": [
    "## 13. Initialize train state\n",
    "\n",
    "Remember that function initializes both the model parameters and the optimizer\n",
    "and puts both into the training state dataclass that is returned."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Mj6OfdEEIU-o"
   },
   "outputs": [],
   "source": [
    "learning_rate = 0.1\n",
    "momentum = 0.9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "_87fL90dH-0Z"
   },
   "outputs": [],
   "source": [
    "state = create_train_state(init_rng, learning_rate, momentum)\n",
    "del init_rng  # Must not be used anymore."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UqNrWu7kIC9S"
   },
   "source": [
    "## 14. Train and evaluate\n",
    "\n",
    "Once the training and testing is done after 10 epochs, the output should show that your model was able to achieve approximately 99% accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "0nxgS5Z5IsT_"
   },
   "outputs": [],
   "source": [
    "num_epochs = 10\n",
    "batch_size = 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ugGlV3u6Iq1A",
    "outputId": "d0944ddb-8d5d-4e9f-9727-040789ef3f17"
   },
   "outputs": [],
   "source": [
    "for epoch in range(1, num_epochs + 1):\n",
    "  # Use a separate PRNG key to permute image data during shuffling\n",
    "  rng, input_rng = jax.random.split(rng)\n",
    "  # Run an optimization step over a training batch\n",
    "  state = train_epoch(state, train_ds, batch_size, epoch, input_rng)\n",
    "  # Evaluate on the test set after each training epoch \n",
    "  test_loss, test_accuracy = eval_model(state.params, test_ds)\n",
    "  print(' test epoch: %d, loss: %.2f, accuracy: %.2f' % (\n",
    "      epoch, test_loss, test_accuracy * 100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "oKcRiQ89xQkF"
   },
   "source": [
    "Congrats! You made it to the end of the annotated MNIST example. You can revisit\n",
    "the same example, but structured differently as a couple of Python modules, test\n",
    "modules, config files, another Colab, and documentation in Flax's Git repo:\n",
    "\n",
    "https://github.com/google/flax/tree/main/examples/mnist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "annotated_mnist.ipynb",
   "provenance": []
  },
  "interpreter": {
   "hash": "50100d07a2a27af6847cdedde67ae5e97c9798a9e1a9ae21eed9ecf69a9f619c"
  },
  "jupytext": {
   "formats": "ipynb,md:myst",
   "main_language": "python"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
